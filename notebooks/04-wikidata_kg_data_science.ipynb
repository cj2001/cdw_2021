{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we assume that you have already populated your Wikidata (AKA \"Method 2\") database, which was shown in `notebooks/03-wikidata_kg.ipynb`.  We also will assume that you have run the Cypher queries found in `cypher_queries/method2_queries.cql` to do things like update the node labels to the P31 values, segment out both model and holdback data, and create some basic embeddings.\n",
    "\n",
    "If you are running this on Google Colab, run the following cell to import the necessary packages."
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install neo4j"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import re\n",
    "import urllib\n",
    "from pprint import pprint\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "import pprint"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Neo4jConnection:\n",
    "    \n",
    "    def __init__(self, uri, user, pwd):\n",
    "        self.__uri = uri\n",
    "        self.__user = user\n",
    "        self.__pwd = pwd\n",
    "        self.__driver = None\n",
    "        try:\n",
    "            self.__driver = GraphDatabase.driver(self.__uri, auth=(self.__user, self.__pwd))\n",
    "        except Exception as e:\n",
    "            print(\"Failed to create the driver:\", e)\n",
    "        \n",
    "    def close(self):\n",
    "        if self.__driver is not None:\n",
    "            self.__driver.close()\n",
    "        \n",
    "    def query(self, query, parameters=None, db=None):\n",
    "        assert self.__driver is not None, \"Driver not initialized!\"\n",
    "        session = None\n",
    "        response = None\n",
    "        try: \n",
    "            session = self.__driver.session(database=db) if db is not None else self.__driver.session() \n",
    "            response = list(session.run(query, parameters))\n",
    "        except Exception as e:\n",
    "            print(\"Query failed:\", e)\n",
    "        finally: \n",
    "            if session is not None:\n",
    "                session.close()\n",
    "        return response"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# If you are using a Docker container for your DB, use the uncommented line.\n",
    "# conn = Neo4jConnection(uri=\"bolt://some_ip_address:7687\", user=\"neo4j\", pwd=\"some_password\")\n",
    "\n",
    "uri = ''\n",
    "user = 'neo4j'\n",
    "pwd = ''\n",
    "\n",
    "conn = Neo4jConnection(uri=uri, user=user, pwd=pwd)\n",
    "conn.query(\"MATCH (n) RETURN COUNT(n)\")"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Embedding visualization\n",
    "\n",
    "We will begin by looking at whether our embeddings cluster at all in any reasonable way.  We have used a pretty high-dimensional space to create those embeddings though, so we will use t-SNE to do dimensionality reduction for the sake of visualization.  Here we have two categories with 1 = `is_place` and 0 = NOT `is_place`.  We ideally want our embeddings to cluster in some clear fashion to give us some assurances that we are going the right way.\n",
    "\n",
    "### Note\n",
    "\n",
    "We have not really done any tuning of our embeddings.  Embedding tuning is an art unto itself and beyond the scope of this demonstration.  However, the result will be, as you will see, that the embeddings don't cluster very well and the resulting ML models don't product super great results.  The following is more intended for demonstration purposes.  In a real-world, deployable application you will obviously want to put much more effort into creating embeddings that work for you.\n",
    "\n",
    "Also, recall that we have some class imbalance.  There are several ways to deal with it.  For the sake of this demonstration, we will attempt to handle this using some built-in functionality in `scikit-learn`."
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def create_tsne_plot(emb_name='n.n2v_all_nodes', n_components=2, debug=False):\n",
    "    \n",
    "    query_string = '''\n",
    "        MATCH (n:Node)\n",
    "        RETURN n.name, n.type, n.is_place AS category, {} AS vec\n",
    "    '''.format(emb_name)\n",
    "    model_df = pd.DataFrame([dict(_) for _ in conn.query(query_string)])\n",
    "    \n",
    "    if debug:\n",
    "        uniqueValues = model_df['category'].nunique()\n",
    "        print(uniqueValues)\n",
    "    \n",
    "    X_emb = TSNE(n_components=n_components).fit_transform(list(model_df['vec']))\n",
    "    \n",
    "    tsne_df = pd.DataFrame(data = {\n",
    "        'x': [value[0] for value in X_emb],\n",
    "        'y': [value[1] for value in X_emb],\n",
    "        'label': model_df['category']\n",
    "    })\n",
    "    \n",
    "    plt.figure(figsize=(16,10))\n",
    "    s = 30\n",
    "    ax = sns.scatterplot(\n",
    "        x='x', y='y',\n",
    "        palette=sns.color_palette('hls',2),\n",
    "        data=tsne_df,\n",
    "        hue='label',\n",
    "        legend=True, \n",
    "        s=500,\n",
    "        alpha=0.75\n",
    "    )\n",
    "    ax.legend(prop={'size': 20})\n",
    "    plt.xlabel('X Component', fontsize=16)\n",
    "    plt.ylabel('Y Component', fontsize=16)\n",
    "    plt.show\n",
    "\n",
    "    return tsne_df"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tsne_df = create_tsne_plot(emb_name='n.n2v_all_nodes', n_components=2, debug=False)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tsne_df = create_tsne_plot(emb_name='n.frp_all_nodes', n_components=2, debug=False)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ML Modeling\n",
    "\n",
    "There are many ways we could use these embeddings to create a model.  In this example, our goal will be binary classification to predict `is_place` given our different embeddings.  For the sake of simplicity, I am just going to create a support vector machine to demonstrate the general approach.  Obviously you can choose whatever classification model you would like.\n",
    "\n",
    "### Note\n",
    "\n",
    "Neo4j outputs its embeddings in a format that is not entirely compatible with `scikit-learn`.  So `create_X` is a helper function that will reformat those embeddings into something suitable."
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def create_X(df2, emb):\n",
    "\n",
    "    n2v_an_ls = df2[emb].to_list()\n",
    "    n2v_arr = np.array([np.array(x) for x in n2v_an_ls], dtype=object)\n",
    "\n",
    "    print(n2v_arr.shape)\n",
    "    \n",
    "    return n2v_arr\n",
    "\n",
    "\n",
    "def modeler(df, emb_name, y_column_name, k_folds=5, model='linear', show_matrix=True):\n",
    "    \n",
    "    y = df[y_column_name].fillna(0.0).to_numpy()\n",
    "    vec_array = create_X(df, emb_name)\n",
    "    acc_scores = []\n",
    "    \n",
    "    pos = np.count_nonzero(y == 1.0)\n",
    "    neg = y.shape[0] - pos\n",
    "    print('Number of positive: ', pos, ' Number of negative: ', neg)\n",
    "    \n",
    "    for i in range(0, k_folds):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(vec_array, y, test_size=0.25)\n",
    "        clf = svm.SVC(kernel='linear', class_weight='balanced')\n",
    "        clf.fit(X_train, y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(pred, y_test)\n",
    "        acc_scores.append(acc)        \n",
    "        \n",
    "    print('Accuracy scores: ', acc_scores)\n",
    "    print('Mean accuracy: ', np.mean(acc_scores))\n",
    "    \n",
    "    if show_matrix:\n",
    "        matrix = plot_confusion_matrix(clf, X_test, y_test, cmap=plt.cm.Blues, normalize='true')\n",
    "        plt.show(matrix)\n",
    "        plt.show()\n",
    "        \n",
    "    return clf"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "query_string = '''\n",
    "    MATCH (n:Node)\n",
    "    RETURN n.name, n.type, n.is_place AS category, n.n2v_all_nodes AS n2v_vec, n.frp_all_nodes AS frp_vec\n",
    "'''\n",
    "model_df = pd.DataFrame([dict(_) for _ in conn.query(query_string)])\n",
    "model_df.head()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n2v_clf = modeler(model_df, emb_name='n2v_vec', y_column_name='category')"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "frp_clf = modeler(model_df, emb_name='frp_vec', y_column_name='category')"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Observation\n",
    "\n",
    "So those accuracy scores were really nothing to write home about.  But how do the classifiers generated by the training handle predicting unknown data points?\n",
    "\n",
    "For this, I am going to choose some nodes that I know to be places just to see what happens.  Some good ones are \"city of the United States,\" \"Illinois,\" and \"Oceania.\"  \n",
    "\n",
    "Let's just give those a manual try and see what happens."
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def predict_unknown(node_name, emb_name, clf, debug=False):\n",
    "    \n",
    "    query_string = \"MATCH (n:Node {name: '\" + node_name + \"'}) RETURN n.name AS name, n.\" + emb_name + \" AS vec\"\n",
    "    \n",
    "    if debug == True:\n",
    "        print(query_string)\n",
    "        print(type(query_string))\n",
    "        print(emb_name)\n",
    "\n",
    "    unknown_df = pd.DataFrame([dict(_) for _ in conn.query(query_string)])\n",
    "    \n",
    "    vec_array = create_X(unknown_df, emb='vec')\n",
    "    pred = clf.predict(vec_array)\n",
    "    print('Predicted Class: ', pred[0])\n",
    "    \n",
    "    return"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predict_unknown('city of the United States', 'n2v_all_nodes', clf=n2v_clf, debug=False)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Result\n",
    "\n",
    "Disappointing, for sure.  But remember that we have spent no effort in optimizing either the embeddings nor the model.  It would take more time than we have in a 2 hour demonstration to do that.  There are plenty of resources out there to study up on this bit.  \n",
    "\n",
    "# Next steps\n",
    "\n",
    "1. Add more data to the graph (always a good idea when you can and time permits!)\n",
    "2. Optimize the above embeddings (obvious)\n",
    "3. Try GraphSAGE (advantage: takes into account node properties in addition to looking at random-walk approach)\n",
    "\n",
    "## Important note\n",
    "\n",
    "The Graph Data Science library does much more than embeddings!  In particular, I recommend you check out the [node classification](https://neo4j.com/docs/graph-data-science/current/algorithms/ml-models/node-classification/#algorithms-ml-nodeclassification) and [link prediction](https://neo4j.com/docs/graph-data-science/current/algorithms/ml-models/linkprediction/) modeling capabilities.  This small graph might not be able to take much advantage of them, but as the graph gets bigger you might find them to be really helpful!"
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}